import { Account } from "./account";
import { Conversation } from "./conversation";
import * as audio from "./audio";
/**
 * A text-to-speech provider to use for the application.
 *
 * `"default"` means the default TTS engine.
 *
 * `"dasha"` means Dasha.AI's own TTS engine.
 *
 * `"custom"` means using your own TTS via the {@link Application.customTtsProvider}.
 *
 * @see {@link Application.ttsDispatcher}
 */
export declare type TtsProviderName = "default" | "custom" | "dasha";
/**
 * A callback that selects a text-to-speech engine for the conversations.
 *
 * @see {@link Application.ttsDispatcher}
 *
 * @deprecated use {@link Conversation.audio.tts} instead
 */
export declare type TtsDispatcher<TInput extends Record<string, unknown>, TOutput extends Record<string, unknown>> = (conv: Conversation<TInput, TOutput>) => TtsProviderName | Promise<TtsProviderName>;
/**
 * A custom text-to-speech callback.
 *
 * Given a text and voice parameters, the callback must return either
 * an {@link Audio} object, or a Fetch API's [Response] object containing the audio data.
 * Both of them can also be wrapped in a Promise.
 *
 * @example using an external TTS API
 * ```typescript
 * application.customTtsProvider = (text) => fetch(`https://example.com/say?text=${text}`);
 * ```
 *
 * @example using pre-recorded audio files
 * ```typescript
 * application.customTtsProvider = (text) => dasha.audio.fromFile(`/path/to/audio/${text}.mp3`);
 * ```
 */
export declare type CustomTtsProvider = (text: string, voice: {
    speaker: string;
    lang: string;
    emotion: string;
    speed: number;
    variation: number;
}) => Response | audio.Audio | Promise<Response | audio.Audio>;
export declare function synthesize(text: string, voice: {
    speaker: string;
    lang: string;
    emotion: string;
    speed: number;
    variation: number;
}, options: {
    providerName: string;
    account?: Account;
}): Promise<Uint8Array>;
